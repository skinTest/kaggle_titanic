{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162dd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "os.environ[\"JOBLIB_TEMP_FOLDER\"] = r\"D:\\joblib_tmp\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761a4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/train.csv\"\n",
    "test_path = \"../data/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46066a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (train_df, test_df):\n",
    "    df[\"Age_is_missing\"] = df[\"Age\"].isna().astype(int)\n",
    "    df[\"Embarked_is_missing\"] = df[\"Embarked\"].isna().astype(int)\n",
    "\n",
    "feature_cols = [\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Age\",\n",
    "    \"Embarked\",\n",
    "    \"Age_is_missing\",\n",
    "    \"Embarked_is_missing\",\n",
    "]\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df[\"Survived\"].astype(int).copy()\n",
    "X_test = test_df[feature_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a34268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "categorical_features = [\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"Embarked\",\n",
    "    \"Age_is_missing\",\n",
    "    \"Embarked_is_missing\",\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4318a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n",
    "\n",
    "# Split train / holdout ONCE (holdout will be used later)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Fixed baseline hyperparameters (except complexity)\n",
    "BASE_PARAMS = dict(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.02,      # small & safe; LR tuning comes later\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_alpha=0.3,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "max_depth_grid = [1, 2, 3, 4]\n",
    "min_child_weight_grid = [1, 3, 6, 9, 12, 15, 18, 21]\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for md in max_depth_grid:\n",
    "    for mcw in min_child_weight_grid:\n",
    "        xgb = XGBClassifier(\n",
    "            max_depth=md,\n",
    "            min_child_weight=mcw,\n",
    "            **BASE_PARAMS,\n",
    "        )\n",
    "\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"model\", xgb),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            pipe,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"accuracy\",\n",
    "            return_train_score=True,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "        mean_train = cv_results[\"train_score\"].mean()\n",
    "        std_train = cv_results[\"train_score\"].std()\n",
    "        mean_valid = cv_results[\"test_score\"].mean()\n",
    "        std_valid = cv_results[\"test_score\"].std()\n",
    "\n",
    "        overfit_gap = mean_train - mean_valid\n",
    "        alpha_gap = 1.0\n",
    "        beta_std = 1.0\n",
    "        custom_score = mean_valid - alpha_gap * overfit_gap - beta_std * std_valid\n",
    "\n",
    "        search_results.append(\n",
    "            dict(\n",
    "                max_depth=md,\n",
    "                min_child_weight=mcw,\n",
    "                mean_train=mean_train,\n",
    "                std_train=std_train,\n",
    "                mean_valid=mean_valid,\n",
    "                std_valid=std_valid,\n",
    "                overfit_gap=overfit_gap,\n",
    "                custom_score=custom_score,\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Turn into DataFrame and sort\n",
    "results_df = pd.DataFrame(search_results)\n",
    "\n",
    "results_df.to_csv(\"../submissions/xgb_strength.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PARAMS = dict(\n",
    "    n_estimators=500,\n",
    "    max_depth=2,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_alpha=0.3,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "\n",
    "learning_rate = [0.005, 0.01, 0.02, 0.03, 0.05, 0.075, 0.1]\n",
    "min_child_weight_grid = [6, 12, 18]\n",
    "\n",
    "search_results = []\n",
    "\n",
    "\n",
    "for lr in learning_rate:\n",
    "    for mcw in min_child_weight_grid:\n",
    "        xgb = XGBClassifier(\n",
    "            learning_rate=lr,\n",
    "            min_child_weight=mcw,\n",
    "            **BASE_PARAMS,\n",
    "        )\n",
    "\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocess\", preprocessor),\n",
    "                (\"model\", xgb),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        cv_results = cross_validate(\n",
    "            pipe,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"accuracy\",\n",
    "            return_train_score=True,\n",
    "            n_jobs=1,\n",
    "        )\n",
    "\n",
    "        mean_train = cv_results[\"train_score\"].mean()\n",
    "        std_train = cv_results[\"train_score\"].std()\n",
    "        mean_valid = cv_results[\"test_score\"].mean()\n",
    "        std_valid = cv_results[\"test_score\"].std()\n",
    "\n",
    "        overfit_gap = mean_train - mean_valid\n",
    "        alpha_gap = 1.0\n",
    "        beta_std = 1.0\n",
    "        custom_score = mean_valid - alpha_gap * overfit_gap - beta_std * std_valid\n",
    "\n",
    "        search_results.append(\n",
    "            dict(\n",
    "                learning_rate=lr,\n",
    "                min_child_weight=mcw,\n",
    "                mean_train=mean_train,\n",
    "                std_train=std_train,\n",
    "                mean_valid=mean_valid,\n",
    "                std_valid=std_valid,\n",
    "                overfit_gap=overfit_gap,\n",
    "                custom_score=custom_score,\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Turn into DataFrame and sort\n",
    "results_df = pd.DataFrame(search_results)\n",
    "\n",
    "results_df.to_csv(\"../submissions/xgb_cv_acc_lr.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
