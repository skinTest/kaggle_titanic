{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed344a8b",
   "metadata": {},
   "source": [
    "# Titanic: Clean FE + XGBoost Notebook\n",
    "This notebook is organized **from scratch** to avoid feature mismatch issues (e.g., missing `Name`).\n",
    "It includes:\n",
    "- clean data loading (keep raw columns)\n",
    "- feature engineering transformer (Title, Cabin, Ticket groups, Family, rule-features)\n",
    "- train/holdout evaluation\n",
    "- optional XGBoost early stopping\n",
    "- Kaggle submission export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1512a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "os.environ[\"JOBLIB_TEMP_FOLDER\"] = r\"D:\\joblib_tmp\"\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e30a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "TRAIN_PATH = \"../data/train.csv\"   # change if needed\n",
    "TEST_PATH  = \"../data/test.csv\"    # change if needed\n",
    "\n",
    "TARGET_COL = \"Survived\"\n",
    "ID_COL = \"PassengerId\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0df3a",
   "metadata": {},
   "source": [
    "## 1) Load raw data (keep original columns)\n",
    "Important: we keep `Name`, `Ticket`, `Cabin` etc. Feature engineering needs them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf32618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 11) Target: (891,) Test shape: (418, 11)\n",
      "Columns: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "def load_raw(train_path=TRAIN_PATH, test_path=TEST_PATH):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "\n",
    "    y = train[TARGET_COL].astype(int)\n",
    "    X = train.drop(columns=[TARGET_COL])\n",
    "    X_test = test.copy()\n",
    "\n",
    "    # Safety checks\n",
    "    assert ID_COL in X.columns and ID_COL in X_test.columns\n",
    "    return X, y, X_test\n",
    "\n",
    "df_train, y_train, df_test = load_raw()\n",
    "print(\"Train shape:\", df_train.shape, \"Target:\", y_train.shape, \"Test shape:\", df_test.shape)\n",
    "print(\"Columns:\", list(df_train.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c7d43",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering Transformer\n",
    "Creates:\n",
    "- TitleGroup\n",
    "- AgeImputed (Title+Pclass median)\n",
    "- FamilySize / IsAlone / SmallFamily / LargeFamily\n",
    "- HasCabin\n",
    "- TicketGroupSize\n",
    "- FareLog / FarePerPersonLog / IsFareZero\n",
    "- Rule-features (IsUpperClassFemale, IsUpperClassBoy)\n",
    "\n",
    "It is robust to missing columns: if a column isn't present, it falls back safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dacd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicFE(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, boy_age_cutoff=10, upper_class_max=2):\n",
    "        self.boy_age_cutoff = boy_age_cutoff\n",
    "        self.upper_class_max = upper_class_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Embarked mode\n",
    "        if \"Embarked\" in X.columns:\n",
    "            mode = X[\"Embarked\"].mode(dropna=True)\n",
    "            self.embarked_mode_ = mode.iloc[0] if len(mode) else \"S\"\n",
    "        else:\n",
    "            self.embarked_mode_ = \"S\"\n",
    "\n",
    "        # Age medians by (Title, Pclass)\n",
    "        title = self._safe_title_series(X)\n",
    "        pclass = X[\"Pclass\"] if \"Pclass\" in X.columns else pd.Series([3]*len(X), index=X.index)\n",
    "        age = X[\"Age\"] if \"Age\" in X.columns else pd.Series([np.nan]*len(X), index=X.index)\n",
    "\n",
    "        tmp = pd.DataFrame({\"Title\": title, \"Pclass\": pclass, \"Age\": age})\n",
    "        self.age_median_by_title_pclass_ = tmp.groupby([\"Title\", \"Pclass\"])[\"Age\"].median()\n",
    "        self.age_global_median_ = float(tmp[\"Age\"].median()) if tmp[\"Age\"].notna().any() else 30.0\n",
    "\n",
    "        # Ticket counts (train-only; safe, no target)\n",
    "        if \"Ticket\" in X.columns:\n",
    "            self.ticket_counts_ = X[\"Ticket\"].value_counts()\n",
    "        else:\n",
    "            self.ticket_counts_ = pd.Series(dtype=int)\n",
    "\n",
    "        # Fare median\n",
    "        if \"Fare\" in X.columns and X[\"Fare\"].notna().any():\n",
    "            self.fare_median_ = float(X[\"Fare\"].median())\n",
    "        else:\n",
    "            self.fare_median_ = 0.0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure expected columns exist\n",
    "        for col, default in [\n",
    "            (\"Pclass\", 3),\n",
    "            (\"Sex\", \"male\"),\n",
    "            (\"Age\", np.nan),\n",
    "            (\"SibSp\", 0),\n",
    "            (\"Parch\", 0),\n",
    "            (\"Fare\", np.nan),\n",
    "            (\"Embarked\", np.nan),\n",
    "            (\"Cabin\", np.nan),\n",
    "            (\"Ticket\", \"UNKNOWN\"),\n",
    "            (\"Name\", np.nan),\n",
    "        ]:\n",
    "            if col not in X.columns:\n",
    "                X[col] = default\n",
    "\n",
    "        # Embarked\n",
    "        X[\"Embarked\"] = X[\"Embarked\"].fillna(self.embarked_mode_)\n",
    "\n",
    "        # Title & grouped title\n",
    "        X[\"Title\"] = X[\"Name\"].map(self._extract_title)\n",
    "        X[\"TitleGroup\"] = X[\"Title\"].map(self._title_group).fillna(\"Rare\")\n",
    "\n",
    "        # Age imputation (Title+Pclass median)\n",
    "        X['IsAgeMissing'] = X['Age'].isna().astype(int)\n",
    "        X[\"AgeImputed\"] = X[\"Age\"]\n",
    "        mask = X[\"AgeImputed\"].isna()\n",
    "        if mask.any():\n",
    "            keys = list(zip(X.loc[mask, \"Title\"], X.loc[mask, \"Pclass\"]))\n",
    "            fills = [self.age_median_by_title_pclass_.get(k, self.age_global_median_) for k in keys]\n",
    "            X.loc[mask, \"AgeImputed\"] = fills\n",
    "\n",
    "        # Family\n",
    "        X[\"FamilySize\"] = X[\"SibSp\"].fillna(0) + X[\"Parch\"].fillna(0) + 1\n",
    "        X[\"IsAlone\"] = (X[\"FamilySize\"] == 1).astype(int)\n",
    "        X[\"SmallFamily\"] = X[\"FamilySize\"].between(2, 4).astype(int)\n",
    "        X[\"LargeFamily\"] = (X[\"FamilySize\"] >= 5).astype(int)\n",
    "\n",
    "        # Cabin\n",
    "        X[\"HasCabin\"] = X[\"Cabin\"].notna().astype(int)\n",
    "\n",
    "        # Fare\n",
    "        X[\"Fare\"] = X[\"Fare\"].fillna(self.fare_median_)\n",
    "        X[\"IsFareZero\"] = (X[\"Fare\"] == 0).astype(int)\n",
    "        X[\"FareLog\"] = np.log1p(X[\"Fare\"])\n",
    "        X[\"FarePerPerson\"] = X[\"Fare\"] / X[\"FamilySize\"].clip(lower=1)\n",
    "        X[\"FarePerPersonLog\"] = np.log1p(X[\"FarePerPerson\"])\n",
    "\n",
    "        # Ticket group size\n",
    "        X[\"TicketGroupSize\"] = X[\"Ticket\"].map(self.ticket_counts_).fillna(1).astype(int)\n",
    "        X[\"IsGroupTicket\"] = (X[\"TicketGroupSize\"] > 1).astype(int)\n",
    "\n",
    "        # Rule features\n",
    "        X[\"IsUpperClass\"] = (X[\"Pclass\"] <= self.upper_class_max).astype(int)\n",
    "        X[\"IsFemale\"] = (X[\"Sex\"] == \"female\").astype(int)\n",
    "        X[\"IsBoy\"] = ((X[\"Sex\"] == \"male\") & (X[\"AgeImputed\"] <= self.boy_age_cutoff)).astype(int)\n",
    "        X[\"IsUpperClassFemale\"] = (X[\"IsUpperClass\"] & X[\"IsFemale\"]).astype(int)\n",
    "        X[\"IsUpperClassBoy\"] = (X[\"IsUpperClass\"] & X[\"IsBoy\"]).astype(int)\n",
    "        X[\"IsLowerClassStrongFemale\"] = ((X[\"IsUpperClass\"] == 0) & (X[\"IsFemale\"] == 1) & (X[\"SmallFamily\"] == 1)).astype(int)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _safe_title_series(self, X):\n",
    "        if \"Name\" not in X.columns:\n",
    "            return pd.Series([\"Unknown\"] * len(X), index=X.index)\n",
    "        return X[\"Name\"].map(self._extract_title)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_title(name):\n",
    "        if pd.isna(name):\n",
    "            return \"Unknown\"\n",
    "        s = str(name)\n",
    "        if \",\" in s and \".\" in s:\n",
    "            return s.split(\",\")[1].split(\".\")[0].strip()\n",
    "        return \"Unknown\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _title_group(title):\n",
    "        if title in [\"Mr\"]:\n",
    "            return \"Mr\"\n",
    "        if title in [\"Mrs\", \"Mme\"]:\n",
    "            return \"Mrs\"\n",
    "        if title in [\"Miss\", \"Mlle\", \"Ms\"]:\n",
    "            return \"Miss\"\n",
    "        if title in [\"Master\"]:\n",
    "            return \"Master\"\n",
    "\n",
    "        noble_female = {\"Lady\", \"Countess\", \"Dona\"}\n",
    "        rare_male = {\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\", \"Sir\", \"Don\", \"Jonkheer\"}\n",
    "\n",
    "        if title in noble_female:\n",
    "            return \"noble_female\"\n",
    "        if title in rare_male:\n",
    "            return \"Rare_Male\"\n",
    "        return \"Rare\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a119f",
   "metadata": {},
   "source": [
    "## 4) Preprocessing (OneHot + StandardScaler)\n",
    "We use FE output columns. This is the most common and robust setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9084d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = [\n",
    "    \"AgeImputed\",\n",
    "    \"FareLog\",\n",
    "    \"FarePerPersonLog\",\n",
    "    \"FamilySize\",\n",
    "    \"TicketGroupSize\",\n",
    "]\n",
    "\n",
    "CAT_COLS = [\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"IsAgeMissing\",\n",
    "    \"Embarked\",\n",
    "    \"TitleGroup\",\n",
    "    \"HasCabin\",\n",
    "    \"IsAlone\",\n",
    "    \"SmallFamily\",\n",
    "    \"LargeFamily\",\n",
    "    \"IsUpperClassFemale\",\n",
    "    \"IsUpperClassBoy\",\n",
    "    \"IsFareZero\",\n",
    "    \"IsGroupTicket\",\n",
    "    \"IsLowerClassStrongFemale\"\n",
    "]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUM_COLS),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232769e6",
   "metadata": {},
   "source": [
    "## 5) Model (XGBoost)\n",
    "Start with your stable config. We'll later try (depth=3) and/or early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e7919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------- config ----------------\n",
    "MCW_GRID = [i for i in range(1, 21)]\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# data (as you stated)\n",
    "X_full = df_train.copy()\n",
    "y_full = y_train.astype(int).to_numpy()\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    n_repeats=N_REPEATS,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "\n",
    "BASE_PARAMS = dict(\n",
    "    max_depth=2,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=800,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_alpha=0.3,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Build full X/y from your new interface\n",
    "X_full = df_train.copy()\n",
    "y_full = y_train.astype(int).to_numpy()\n",
    "\n",
    "assert len(X_full) == len(y_full)\n",
    "assert ID_COL in X_full.columns and ID_COL in df_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f867d5-cec8-4f56-9b60-1340168aa6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcw</th>\n",
       "      <th>cv_mean@0.5</th>\n",
       "      <th>cv_std@0.5</th>\n",
       "      <th>oof_best_thr</th>\n",
       "      <th>oof_best_acc</th>\n",
       "      <th>oof_acc@0.45</th>\n",
       "      <th>oof_acc@0.50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.831277</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.829405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.828646</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.827542</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.826038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.826788</td>\n",
       "      <td>0.013222</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.827160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.825276</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.822671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.824920</td>\n",
       "      <td>0.014179</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.820426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.826038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.824907</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.823793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.824158</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.832772</td>\n",
       "      <td>0.824916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.823798</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.826038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.823786</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.822671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.822288</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.827160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.821173</td>\n",
       "      <td>0.016770</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.817059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.813692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.818923</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.817427</td>\n",
       "      <td>0.017202</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.819304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.816306</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.815937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.816302</td>\n",
       "      <td>0.020839</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.813692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.815929</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.815184</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.817059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mcw  cv_mean@0.5  cv_std@0.5  oof_best_thr  oof_best_acc  oof_acc@0.45  \\\n",
       "8     9     0.831277    0.014959         0.406      0.836139      0.832772   \n",
       "6     7     0.828646    0.015132         0.419      0.838384      0.833895   \n",
       "9    10     0.827542    0.015307         0.408      0.835017      0.829405   \n",
       "7     8     0.826788    0.013222         0.400      0.836139      0.832772   \n",
       "5     6     0.825276    0.014763         0.421      0.837262      0.835017   \n",
       "11   12     0.824920    0.014179         0.433      0.832772      0.831650   \n",
       "0     1     0.824910    0.012241         0.438      0.839506      0.835017   \n",
       "1     2     0.824907    0.012273         0.435      0.838384      0.837262   \n",
       "4     5     0.824158    0.011484         0.418      0.835017      0.832772   \n",
       "10   11     0.823798    0.015383         0.443      0.835017      0.831650   \n",
       "2     3     0.823786    0.011301         0.433      0.836139      0.833895   \n",
       "3     4     0.822288    0.012363         0.445      0.835017      0.833895   \n",
       "12   13     0.821173    0.016770         0.436      0.835017      0.833895   \n",
       "13   14     0.819304    0.017297         0.436      0.835017      0.831650   \n",
       "14   15     0.818923    0.019670         0.449      0.833895      0.833895   \n",
       "19   20     0.817427    0.017202         0.453      0.830527      0.829405   \n",
       "16   17     0.816306    0.018328         0.462      0.831650      0.829405   \n",
       "15   16     0.816302    0.020839         0.454      0.833895      0.831650   \n",
       "18   19     0.815929    0.016893         0.454      0.829405      0.828283   \n",
       "17   18     0.815184    0.016249         0.468      0.830527      0.828283   \n",
       "\n",
       "    oof_acc@0.50  \n",
       "8       0.829405  \n",
       "6       0.828283  \n",
       "9       0.826038  \n",
       "7       0.827160  \n",
       "5       0.822671  \n",
       "11      0.820426  \n",
       "0       0.826038  \n",
       "1       0.823793  \n",
       "4       0.824916  \n",
       "10      0.826038  \n",
       "2       0.822671  \n",
       "3       0.827160  \n",
       "12      0.817059  \n",
       "13      0.813692  \n",
       "14      0.814815  \n",
       "19      0.819304  \n",
       "16      0.815937  \n",
       "15      0.813692  \n",
       "18      0.818182  \n",
       "17      0.817059  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mcw in MCW_GRID:\n",
    "    xgb = XGBClassifier(\n",
    "        min_child_weight=mcw,\n",
    "        **BASE_PARAMS\n",
    "    )\n",
    "\n",
    "    pipe_template = Pipeline([\n",
    "        (\"fe\", TitanicFE(boy_age_cutoff=10, upper_class_max=2)),\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", xgb),\n",
    "    ])\n",
    "\n",
    "    oof_proba = np.zeros(len(X_full))\n",
    "    oof_count = np.zeros(len(X_full), dtype=int)\n",
    "    fold_acc = []\n",
    "\n",
    "    for tr_idx, va_idx in rskf.split(X_full, y_full):\n",
    "        model = clone(pipe_template)\n",
    "\n",
    "        X_tr, X_va = X_full.iloc[tr_idx], X_full.iloc[va_idx]\n",
    "        y_tr, y_va = y_full[tr_idx], y_full[va_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        va_proba = model.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        # accuracy at default threshold 0.5\n",
    "        va_pred_05 = (va_proba >= 0.5).astype(int)\n",
    "        fold_acc.append(accuracy_score(y_va, va_pred_05))\n",
    "\n",
    "        oof_proba[va_idx] += va_proba\n",
    "        oof_count[va_idx] += 1\n",
    "\n",
    "    # finalize OOF\n",
    "    oof_proba /= oof_count\n",
    "\n",
    "    # threshold search on OOF\n",
    "    ths = np.linspace(0.40, 0.55, 151)\n",
    "    oof_accs = [\n",
    "        accuracy_score(y_full, (oof_proba >= t).astype(int))\n",
    "        for t in ths\n",
    "    ]\n",
    "    best_i = int(np.argmax(oof_accs))\n",
    "    best_thr = float(ths[best_i])\n",
    "    best_oof_acc = float(oof_accs[best_i])\n",
    "\n",
    "    rows.append({\n",
    "        \"mcw\": mcw,\n",
    "        \"cv_mean@0.5\": np.mean(fold_acc),\n",
    "        \"cv_std@0.5\":  np.std(fold_acc),\n",
    "        \"oof_best_thr\": best_thr,\n",
    "        \"oof_best_acc\": best_oof_acc,\n",
    "        \"oof_acc@0.45\": accuracy_score(y_full, (oof_proba >= 0.45).astype(int)),\n",
    "        \"oof_acc@0.50\": accuracy_score(y_full, (oof_proba >= 0.50).astype(int)),\n",
    "    })\n",
    "\n",
    "mcw_table = pd.DataFrame(rows).sort_values(\"cv_mean@0.5\", ascending=False)\n",
    "mcw_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df85313-fea1-4017-9a35-cf3abb23f29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV acc mean @0.5: 0.8267884418220242\n",
      "CV acc std  @0.5: 0.013222072501671003\n",
      "Models trained: 15\n",
      "Saved submission: submissions\\submission_xgb_fe_ageMissing_mcw8_rskf5x3_thr0.600_20251226_153330.csv\n",
      "Saved meta: submissions\\meta_xgb_fe_ageMissing_mcw8_rskf5x3_thr0.600_20251226_153330.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "BEST_MCW = 8\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "OUT_DIR = \"submissions\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Your data interface (as you described)\n",
    "X_full = df_train.copy()                      # already dropped TARGET_COL\n",
    "y_full = y_train.astype(int).to_numpy()\n",
    "X_test = df_test.copy()\n",
    "\n",
    "assert len(X_full) == len(y_full)\n",
    "assert ID_COL in X_full.columns and ID_COL in X_test.columns\n",
    "\n",
    "# ----------------------------\n",
    "# Build pipeline template (cloned each fold)\n",
    "# ----------------------------\n",
    "xgb = XGBClassifier(\n",
    "    min_child_weight=BEST_MCW,\n",
    "    **BASE_PARAMS\n",
    ")\n",
    "\n",
    "pipe_template = Pipeline(steps=[\n",
    "    (\"fe\", TitanicFE(boy_age_cutoff=10, upper_class_max=2)),\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", xgb),\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# CV loop: OOF + test proba averaging\n",
    "# ----------------------------\n",
    "rskf = RepeatedStratifiedKFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    n_repeats=N_REPEATS,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "oof_proba = np.zeros(len(X_full), dtype=float)\n",
    "oof_count = np.zeros(len(X_full), dtype=int)\n",
    "\n",
    "test_proba_sum = np.zeros(len(X_test), dtype=float)\n",
    "fold_acc = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(rskf.split(X_full, y_full), start=1):\n",
    "    model = clone(pipe_template)\n",
    "\n",
    "    X_tr, X_va = X_full.iloc[tr_idx], X_full.iloc[va_idx]\n",
    "    y_tr, y_va = y_full[tr_idx], y_full[va_idx]\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    va_proba = model.predict_proba(X_va)[:, 1]\n",
    "    va_pred_05 = (va_proba >= 0.5).astype(int)\n",
    "    fold_acc.append(accuracy_score(y_va, va_pred_05))\n",
    "\n",
    "    oof_proba[va_idx] += va_proba\n",
    "    oof_count[va_idx] += 1\n",
    "\n",
    "    test_proba_sum += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# finalize oof + test\n",
    "oof_proba /= np.maximum(oof_count, 1)\n",
    "n_models = N_SPLITS * N_REPEATS\n",
    "test_proba_avg = test_proba_sum / n_models\n",
    "\n",
    "print(\"CV acc mean @0.5:\", float(np.mean(fold_acc)))\n",
    "print(\"CV acc std  @0.5:\", float(np.std(fold_acc)))\n",
    "print(\"Models trained:\", n_models)\n",
    "\n",
    "# ----------------------------\n",
    "# Threshold choice\n",
    "# Option A (recommended): fixed threshold from your table region\n",
    "# ----------------------------\n",
    "THRESHOLD = 0.60\n",
    "\n",
    "# Option B: best threshold on OOF (slightly optimistic but ok)\n",
    "# ths = np.linspace(0.35, 0.55, 201)\n",
    "# accs = [accuracy_score(y_full, (oof_proba >= t).astype(int)) for t in ths]\n",
    "# THRESHOLD = float(ths[int(np.argmax(accs))])\n",
    "# print(\"Chosen OOF-best threshold:\", THRESHOLD)\n",
    "\n",
    "# ----------------------------\n",
    "# Create submission\n",
    "# ----------------------------\n",
    "test_pred = (test_proba_avg >= THRESHOLD).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: X_test[ID_COL].values,\n",
    "    TARGET_COL: test_pred\n",
    "})\n",
    "\n",
    "assert len(submission) == len(X_test)\n",
    "assert submission[ID_COL].is_unique\n",
    "assert submission[TARGET_COL].isin([0, 1]).all()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_tag = f\"xgb_fe_ageMissing_mcw{BEST_MCW}_rskf{N_SPLITS}x{N_REPEATS}_thr{THRESHOLD:.3f}\"\n",
    "\n",
    "csv_path = os.path.join(OUT_DIR, f\"submission_{run_tag}_{timestamp}.csv\")\n",
    "meta_path = os.path.join(OUT_DIR, f\"meta_{run_tag}_{timestamp}.json\")\n",
    "\n",
    "submission.to_csv(csv_path, index=False)\n",
    "\n",
    "meta = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"run_tag\": run_tag,\n",
    "    \"mcw\": BEST_MCW,\n",
    "    \"threshold\": THRESHOLD,\n",
    "    \"cv_mean_at_0p5\": float(np.mean(fold_acc)),\n",
    "    \"cv_std_at_0p5\": float(np.std(fold_acc)),\n",
    "    \"base_params\": BASE_PARAMS,\n",
    "    \"n_splits\": N_SPLITS,\n",
    "    \"n_repeats\": N_REPEATS,\n",
    "    \"n_models\": n_models\n",
    "}\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved submission:\", csv_path)\n",
    "print(\"Saved meta:\", meta_path)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ba39e-68a1-4c9c-ab5b-1d45c80de4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed528b91-14bc-4024-8fdf-d08d828c5764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e7436-62ec-4d45-8b8d-718684fd8a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
