{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed344a8b",
   "metadata": {},
   "source": [
    "# Titanic: Clean FE + XGBoost Notebook\n",
    "This notebook is organized **from scratch** to avoid feature mismatch issues (e.g., missing `Name`).\n",
    "It includes:\n",
    "- clean data loading (keep raw columns)\n",
    "- feature engineering transformer (Title, Cabin, Ticket groups, Family, rule-features)\n",
    "- train/holdout evaluation\n",
    "- optional XGBoost early stopping\n",
    "- Kaggle submission export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1512a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "os.environ[\"JOBLIB_TEMP_FOLDER\"] = r\"D:\\joblib_tmp\"\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e30a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "RANDOM_STATE = 2025\n",
    "\n",
    "TRAIN_PATH = \"../data/train.csv\"   # change if needed\n",
    "TEST_PATH  = \"../data/test.csv\"    # change if needed\n",
    "\n",
    "TARGET_COL = \"Survived\"\n",
    "ID_COL = \"PassengerId\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d0df3a",
   "metadata": {},
   "source": [
    "## 1) Load raw data (keep original columns)\n",
    "Important: we keep `Name`, `Ticket`, `Cabin` etc. Feature engineering needs them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf32618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 11) Target: (891,) Test shape: (418, 11)\n",
      "Columns: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "def load_raw(train_path=TRAIN_PATH, test_path=TEST_PATH):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "\n",
    "    y = train[TARGET_COL].astype(int)\n",
    "    X = train.drop(columns=[TARGET_COL])\n",
    "    X_test = test.copy()\n",
    "\n",
    "    # Safety checks\n",
    "    assert ID_COL in X.columns and ID_COL in X_test.columns\n",
    "    return X, y, X_test\n",
    "\n",
    "X, y, X_test = load_raw()\n",
    "print(\"Train shape:\", X.shape, \"Target:\", y.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"Columns:\", list(X.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ac3e8",
   "metadata": {},
   "source": [
    "## 2) Split train/holdout\n",
    "Holdout is used as a reality check (prevents CV overfitting during feature iteration).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a505f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: (712, 11) Holdout: (179, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "print(\"Train split:\", X_train.shape, \"Holdout:\", X_holdout.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d638892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket\n",
       "CA. 2343              7\n",
       "382652                5\n",
       "347082                5\n",
       "CA 2144               5\n",
       "W./C. 6608            4\n",
       "                     ..\n",
       "PC 17474              1\n",
       "A/5. 13032            1\n",
       "370365                1\n",
       "SOTON/O.Q. 3101307    1\n",
       "244358                1\n",
       "Name: count, Length: 563, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.copy()\n",
    "X[\"Ticket\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c7d43",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering Transformer\n",
    "Creates:\n",
    "- TitleGroup\n",
    "- AgeImputed (Title+Pclass median)\n",
    "- FamilySize / IsAlone / SmallFamily / LargeFamily\n",
    "- HasCabin\n",
    "- TicketGroupSize\n",
    "- FareLog / FarePerPersonLog / IsFareZero\n",
    "- Rule-features (IsUpperClassFemale, IsUpperClassBoy)\n",
    "\n",
    "It is robust to missing columns: if a column isn't present, it falls back safely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dacd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicFE(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, boy_age_cutoff=10, upper_class_max=2):\n",
    "        self.boy_age_cutoff = boy_age_cutoff\n",
    "        self.upper_class_max = upper_class_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Embarked mode\n",
    "        if \"Embarked\" in X.columns:\n",
    "            mode = X[\"Embarked\"].mode(dropna=True)\n",
    "            self.embarked_mode_ = mode.iloc[0] if len(mode) else \"S\"\n",
    "        else:\n",
    "            self.embarked_mode_ = \"S\"\n",
    "\n",
    "        # Age medians by (Title, Pclass)\n",
    "        title = self._safe_title_series(X)\n",
    "        pclass = X[\"Pclass\"] if \"Pclass\" in X.columns else pd.Series([3]*len(X), index=X.index)\n",
    "        age = X[\"Age\"] if \"Age\" in X.columns else pd.Series([np.nan]*len(X), index=X.index)\n",
    "\n",
    "        tmp = pd.DataFrame({\"Title\": title, \"Pclass\": pclass, \"Age\": age})\n",
    "        self.age_median_by_title_pclass_ = tmp.groupby([\"Title\", \"Pclass\"])[\"Age\"].median()\n",
    "        self.age_global_median_ = float(tmp[\"Age\"].median()) if tmp[\"Age\"].notna().any() else 30.0\n",
    "\n",
    "        # Ticket counts (train-only; safe, no target)\n",
    "        if \"Ticket\" in X.columns:\n",
    "            self.ticket_counts_ = X[\"Ticket\"].value_counts()\n",
    "        else:\n",
    "            self.ticket_counts_ = pd.Series(dtype=int)\n",
    "\n",
    "        # Fare median\n",
    "        if \"Fare\" in X.columns and X[\"Fare\"].notna().any():\n",
    "            self.fare_median_ = float(X[\"Fare\"].median())\n",
    "        else:\n",
    "            self.fare_median_ = 0.0\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Ensure expected columns exist\n",
    "        for col, default in [\n",
    "            (\"Pclass\", 3),\n",
    "            (\"Sex\", \"male\"),\n",
    "            (\"Age\", np.nan),\n",
    "            (\"SibSp\", 0),\n",
    "            (\"Parch\", 0),\n",
    "            (\"Fare\", np.nan),\n",
    "            (\"Embarked\", np.nan),\n",
    "            (\"Cabin\", np.nan),\n",
    "            (\"Ticket\", \"UNKNOWN\"),\n",
    "            (\"Name\", np.nan),\n",
    "        ]:\n",
    "            if col not in X.columns:\n",
    "                X[col] = default\n",
    "\n",
    "        # Embarked\n",
    "        X[\"Embarked\"] = X[\"Embarked\"].fillna(self.embarked_mode_)\n",
    "\n",
    "        # Title & grouped title\n",
    "        X[\"Title\"] = X[\"Name\"].map(self._extract_title)\n",
    "        X[\"TitleGroup\"] = X[\"Title\"].map(self._title_group).fillna(\"Rare\")\n",
    "\n",
    "        # Age imputation (Title+Pclass median)\n",
    "        X['AgeIsMissing'] = X['Age'].isna().astype(int)\n",
    "        X[\"AgeImputed\"] = X[\"Age\"]\n",
    "        mask = X[\"AgeImputed\"].isna()\n",
    "        if mask.any():\n",
    "            keys = list(zip(X.loc[mask, \"Title\"], X.loc[mask, \"Pclass\"]))\n",
    "            fills = [self.age_median_by_title_pclass_.get(k, self.age_global_median_) for k in keys]\n",
    "            X.loc[mask, \"AgeImputed\"] = fills\n",
    "\n",
    "        # Family\n",
    "        X[\"FamilySize\"] = X[\"SibSp\"].fillna(0) + X[\"Parch\"].fillna(0) + 1\n",
    "        X[\"IsAlone\"] = (X[\"FamilySize\"] == 1).astype(int)\n",
    "        X[\"SmallFamily\"] = X[\"FamilySize\"].between(2, 4).astype(int)\n",
    "        X[\"LargeFamily\"] = (X[\"FamilySize\"] >= 5).astype(int)\n",
    "\n",
    "        # Cabin\n",
    "        X[\"HasCabin\"] = X[\"Cabin\"].notna().astype(int)\n",
    "\n",
    "        # Fare\n",
    "        X[\"Fare\"] = X[\"Fare\"].fillna(self.fare_median_)\n",
    "        X[\"IsFareZero\"] = (X[\"Fare\"] == 0).astype(int)\n",
    "        X[\"FareLog\"] = np.log1p(X[\"Fare\"])\n",
    "        X[\"FarePerPerson\"] = X[\"Fare\"] / X[\"FamilySize\"].clip(lower=1)\n",
    "        X[\"FarePerPersonLog\"] = np.log1p(X[\"FarePerPerson\"])\n",
    "\n",
    "        # Ticket group size\n",
    "        X[\"TicketGroupSize\"] = X[\"Ticket\"].map(self.ticket_counts_).fillna(1).astype(int)\n",
    "        X[\"IsGroupTicket\"] = (X[\"TicketGroupSize\"] > 1).astype(int)\n",
    "\n",
    "        # Rule features\n",
    "        X[\"IsUpperClass\"] = (X[\"Pclass\"] <= self.upper_class_max).astype(int)\n",
    "        X[\"IsFemale\"] = (X[\"Sex\"] == \"female\").astype(int)\n",
    "        X[\"IsBoy\"] = ((X[\"Sex\"] == \"male\") & (X[\"AgeImputed\"] <= self.boy_age_cutoff)).astype(int)\n",
    "        X[\"IsUpperClassFemale\"] = (X[\"IsUpperClass\"] & X[\"IsFemale\"]).astype(int)\n",
    "        X[\"IsUpperClassBoy\"] = (X[\"IsUpperClass\"] & X[\"IsBoy\"]).astype(int)\n",
    "        X[\"IsLowerClassStrongFemale\"] = ((X[\"IsUpperClass\"] == 0) & (X[\"IsFemale\"] == 1) & (X[\"SmallFamily\"] == 1)).astype(int)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _safe_title_series(self, X):\n",
    "        if \"Name\" not in X.columns:\n",
    "            return pd.Series([\"Unknown\"] * len(X), index=X.index)\n",
    "        return X[\"Name\"].map(self._extract_title)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_title(name):\n",
    "        if pd.isna(name):\n",
    "            return \"Unknown\"\n",
    "        s = str(name)\n",
    "        if \",\" in s and \".\" in s:\n",
    "            return s.split(\",\")[1].split(\".\")[0].strip()\n",
    "        return \"Unknown\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _title_group(title):\n",
    "        if title in [\"Mr\"]:\n",
    "            return \"Mr\"\n",
    "        if title in [\"Mrs\", \"Mme\"]:\n",
    "            return \"Mrs\"\n",
    "        if title in [\"Miss\", \"Mlle\", \"Ms\"]:\n",
    "            return \"Miss\"\n",
    "        if title in [\"Master\"]:\n",
    "            return \"Master\"\n",
    "\n",
    "        noble_female = {\"Lady\", \"Countess\", \"Dona\"}\n",
    "        rare_male = {\"Dr\", \"Rev\", \"Col\", \"Major\", \"Capt\", \"Sir\", \"Don\", \"Jonkheer\"}\n",
    "\n",
    "        if title in noble_female:\n",
    "            return \"noble_female\"\n",
    "        if title in rare_male:\n",
    "            return \"Rare_Male\"\n",
    "        return \"Rare\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150a119f",
   "metadata": {},
   "source": [
    "## 4) Preprocessing (OneHot + StandardScaler)\n",
    "We use FE output columns. This is the most common and robust setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9084d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLS = [\n",
    "    \"AgeImputed\",\n",
    "    \"FareLog\",\n",
    "    \"FarePerPersonLog\",\n",
    "    \"FamilySize\",\n",
    "    \"TicketGroupSize\",\n",
    "]\n",
    "\n",
    "CAT_COLS = [\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"AgeIsMissing\",\n",
    "    \"Embarked\",\n",
    "    \"TitleGroup\",\n",
    "    \"HasCabin\",\n",
    "    \"IsAlone\",\n",
    "    \"SmallFamily\",\n",
    "    \"LargeFamily\",\n",
    "    \"IsUpperClassFemale\",\n",
    "    \"IsUpperClassBoy\",\n",
    "    \"IsFareZero\",\n",
    "    \"IsGroupTicket\",\n",
    "    \"IsLowerClassStrongFemale\"\n",
    "]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUM_COLS),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232769e6",
   "metadata": {},
   "source": [
    "## 5) Model (XGBoost)\n",
    "Start with your stable config. We'll later try (depth=3) and/or early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0e7919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_child_weight=1: holdout_acc=0.7989, train_acc=0.8581, gap=0.0593\n",
      "min_child_weight=2: holdout_acc=0.7989, train_acc=0.8610, gap=0.0621\n",
      "min_child_weight=3: holdout_acc=0.7989, train_acc=0.8610, gap=0.0621\n",
      "min_child_weight=4: holdout_acc=0.7933, train_acc=0.8581, gap=0.0648\n",
      "min_child_weight=5: holdout_acc=0.7933, train_acc=0.8581, gap=0.0648\n",
      "min_child_weight=6: holdout_acc=0.7933, train_acc=0.8610, gap=0.0677\n",
      "min_child_weight=7: holdout_acc=0.7877, train_acc=0.8581, gap=0.0704\n",
      "min_child_weight=8: holdout_acc=0.7933, train_acc=0.8553, gap=0.0620\n",
      "min_child_weight=9: holdout_acc=0.8045, train_acc=0.8483, gap=0.0438\n",
      "min_child_weight=10: holdout_acc=0.7989, train_acc=0.8497, gap=0.0508\n",
      "min_child_weight=11: holdout_acc=0.7933, train_acc=0.8497, gap=0.0564\n",
      "min_child_weight=12: holdout_acc=0.8045, train_acc=0.8497, gap=0.0452\n",
      "min_child_weight=13: holdout_acc=0.8101, train_acc=0.8511, gap=0.0411\n",
      "min_child_weight=14: holdout_acc=0.8156, train_acc=0.8511, gap=0.0355\n",
      "min_child_weight=15: holdout_acc=0.8156, train_acc=0.8455, gap=0.0299\n",
      "min_child_weight=16: holdout_acc=0.8156, train_acc=0.8427, gap=0.0271\n",
      "min_child_weight=17: holdout_acc=0.8156, train_acc=0.8441, gap=0.0285\n",
      "min_child_weight=18: holdout_acc=0.8101, train_acc=0.8427, gap=0.0326\n",
      "min_child_weight=19: holdout_acc=0.8101, train_acc=0.8427, gap=0.0326\n",
      "min_child_weight=20: holdout_acc=0.8101, train_acc=0.8399, gap=0.0298\n",
      "min_child_weight=21: holdout_acc=0.8101, train_acc=0.8413, gap=0.0312\n"
     ]
    }
   ],
   "source": [
    "BASE_PARAMS = dict(\n",
    "    max_depth=2,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=800,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.6,\n",
    "    reg_alpha=0.3,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "min_child_weight_grid = [i for i in range(1, 22)]\n",
    "results = []\n",
    "\n",
    "for mcw in min_child_weight_grid:\n",
    "    xgb = XGBClassifier(\n",
    "        min_child_weight=mcw,\n",
    "        **BASE_PARAMS,\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"fe\", TitanicFE(boy_age_cutoff=10, upper_class_max=2)),\n",
    "        (\"prep\", preprocess),\n",
    "        (\"model\", xgb),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_holdout)\n",
    "\n",
    "    holdout_acc = accuracy_score(y_holdout, y_pred)\n",
    "    train_acc = accuracy_score(y_train, pipe.predict(X_train))\n",
    "    gap = train_acc - holdout_acc\n",
    "\n",
    "    results.append({\n",
    "        \"min_child_weight\": mcw,\n",
    "        \"holdout_acc\": holdout_acc,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"gap\": gap\n",
    "    })\n",
    "\n",
    "    print(f\"min_child_weight={mcw}: holdout_acc={holdout_acc:.4f}, train_acc={train_acc:.4f}, gap={gap:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12aea27",
   "metadata": {},
   "source": [
    "## 6) Fit + Evaluate (Train vs Holdout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de931b",
   "metadata": {},
   "source": [
    "## 7) Kaggle Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820f9b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on full training data, predict on test\n",
    "pipe.fit(X, y)\n",
    "test_pred = pipe.predict(X_test).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": X_test[ID_COL],\n",
    "    \"Survived\": test_pred\n",
    "})\n",
    "\n",
    "# Safety checks\n",
    "assert len(submission) == len(X_test)\n",
    "assert submission[\"PassengerId\"].is_unique\n",
    "assert submission[\"Survived\"].isin([0,1]).all()\n",
    "\n",
    "submission.to_csv(\"submission_xgb_fe.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f867d5-cec8-4f56-9b60-1340168aa6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df85313-fea1-4017-9a35-cf3abb23f29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2608703-02bd-4e08-aace-e9cf7b9c97d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ba39e-68a1-4c9c-ab5b-1d45c80de4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed528b91-14bc-4024-8fdf-d08d828c5764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e7436-62ec-4d45-8b8d-718684fd8a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
